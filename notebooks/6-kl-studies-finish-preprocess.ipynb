{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6d0f7f",
   "metadata": {},
   "source": [
    "# <font color='violet'> Feature Engineering for Review Language \n",
    "\n",
    "On data that I started pre-processing here: https://github.com/fractaldatalearning/psychedelic_efficacy/blob/main/notebooks/5-kl-studies-lang-eda-preprocess.ipynb\n",
    "    \n",
    "Try multiple methods for engineering features out of the text of the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7950e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_lg\n",
    "# ! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa92868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import spacy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from gensim.models.fasttext import FastText, load_facebook_model\n",
    "\n",
    "# Might need to do this:\n",
    "# import fasttext.util\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "# ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c010b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31559 entries, 0 to 31558\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   rating             31559 non-null  float64\n",
      " 1   condition          31559 non-null  object \n",
      " 2   review             31559 non-null  object \n",
      " 3   date               31451 non-null  object \n",
      " 4   drug0              31559 non-null  object \n",
      " 5   drug1              18992 non-null  object \n",
      " 6   review_len         31559 non-null  int64  \n",
      " 7   complexity         31559 non-null  float64\n",
      " 8   spell_corr         31559 non-null  object \n",
      " 9   no_stops_lemm      31558 non-null  object \n",
      " 10  no_stop_cap_lemm   31558 non-null  object \n",
      " 11  subjectivity       31559 non-null  float64\n",
      " 12  original_polarity  31559 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/studies_w_sentiment.csv').drop(columns=['Unnamed: 0'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf0dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31559 entries, 0 to 31558\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   rating             31559 non-null  float64\n",
      " 1   condition          31559 non-null  object \n",
      " 2   date               31451 non-null  object \n",
      " 3   drug0              31559 non-null  object \n",
      " 4   drug1              18992 non-null  object \n",
      " 5   review_len         31559 non-null  int64  \n",
      " 6   complexity         31559 non-null  float64\n",
      " 7   no_stop_cap_lemm   31558 non-null  object \n",
      " 8   subjectivity       31559 non-null  float64\n",
      " 9   original_polarity  31559 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# I'll just be using the cleanest text\n",
    "df = df.drop(columns=['review', 'spell_corr', 'no_stops_lemm'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06064b",
   "metadata": {},
   "source": [
    "I'll start by engineering features with tfidf. Based on what I found during eda, ngrams through n=4 provided meaningful-seeming phrases, but apart from !!!!, the most commonly-occuring quadgram \"post traumatic stress disorder\" only appeared in less than 1% of reviews. While ptsd could very likely appear later in scrubbed psychedelic experience reports, other quadgrams are unlikely to improve model performance enough to make it worth the over-fitting that comes with including them. So, for tfidf, focus on ngrams 1-3. \n",
    "\n",
    "Speaking of exclamation points, I'd wanted to get rid of exccessive exclamations and reduce each instance to just 3 !!!. Do that real quick, and clean up and null values. I'd kept some null values in place earlier on until I more thoroughly understood the data/ was ready to create a train-test split, and that time has come. With everything clean, things will go smoother with modeling to test out various feature engineering techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60bfc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>condition</th>\n",
       "      <th>date</th>\n",
       "      <th>drug0</th>\n",
       "      <th>drug1</th>\n",
       "      <th>review_len</th>\n",
       "      <th>complexity</th>\n",
       "      <th>no_stop_cap_lemm</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>original_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29472</th>\n",
       "      <td>8.0</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>clonazepam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating condition        date       drug0 drug1  review_len  complexity  \\\n",
       "29472     8.0   anxiety  2016-10-19  clonazepam   NaN           7        -3.5   \n",
       "\n",
       "      no_stop_cap_lemm  subjectivity  original_polarity  \n",
       "29472              NaN           0.0                0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It appears as though stopword deletion left one very short review consisting of nothing\n",
    "# Drop that row, then reset the index so it's in order, in order to replace !!!!. \n",
    "df[df.no_stop_cap_lemm.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a68c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31558 entries, 0 to 31557\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   rating             31558 non-null  float64\n",
      " 1   condition          31558 non-null  object \n",
      " 2   date               31450 non-null  object \n",
      " 3   drug0              31558 non-null  object \n",
      " 4   drug1              18992 non-null  object \n",
      " 5   review_len         31558 non-null  int64  \n",
      " 6   complexity         31558 non-null  float64\n",
      " 7   no_stop_cap_lemm   31558 non-null  object \n",
      " 8   subjectivity       31558 non-null  float64\n",
      " 9   original_polarity  31558 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(labels=29472).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3ebc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>condition</th>\n",
       "      <th>date</th>\n",
       "      <th>drug0</th>\n",
       "      <th>drug1</th>\n",
       "      <th>review_len</th>\n",
       "      <th>complexity</th>\n",
       "      <th>no_stop_cap_lemm</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>original_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>7.0</td>\n",
       "      <td>addiction</td>\n",
       "      <td>2016-08-28</td>\n",
       "      <td>varenicline</td>\n",
       "      <td>chantix</td>\n",
       "      <td>763</td>\n",
       "      <td>4.1</td>\n",
       "      <td>want let everyone know react chantexday 7 8 so...</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>-0.364583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating  condition        date        drug0    drug1  review_len  \\\n",
       "9255     7.0  addiction  2016-08-28  varenicline  chantix         763   \n",
       "\n",
       "      complexity                                   no_stop_cap_lemm  \\\n",
       "9255         4.1  want let everyone know react chantexday 7 8 so...   \n",
       "\n",
       "      subjectivity  original_polarity  \n",
       "9255      0.736111          -0.364583  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That worked. Find some exclamation points that need replacing.\n",
    "df[df.no_stop_cap_lemm.str.find('!!!!!!')!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31db97f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'want let everyone know react chantexday 7 8 soon tired desire mad angry confused know ! get sleep tell need bed set bed ! think computer desk study ! 4 pm asleep 10 time wake all want sleep tired doctoream color tired thankfully hit weekend tomorrow work ! hopefully able ! worry have cigarette anymore really fierceness quit get smoke!!!!!!quit numb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.no_stop_cap_lemm[9255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a83051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31558/31558 [00:22<00:00, 1383.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'want let everyone know react chantexday 7 8 soon tired desire mad angry confused know ! get sleep tell need bed set bed ! think computer desk study ! 4 pm asleep 10 time wake all want sleep tired doctoream color tired thankfully hit weekend tomorrow work ! hopefully able ! worry have cigarette anymore really fierceness quit get smoke!!!quit numb'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclamation_replacement = {'!!!!':'!!!', '!!!!!':'!!!', '!!!!!!':'!!!',\n",
    "                            '!!!!!!!':'!!!', '!!!!!!!!':'!!!'}\n",
    "\n",
    "for row in tqdm(range(len(df))):\n",
    "    str_to_reduce_exclam = df.loc[row,'no_stop_cap_lemm']\n",
    "    for key, value in exclamation_replacement.items():\n",
    "        str_to_reduce_exclam = str_to_reduce_exclam.replace(key,value)\n",
    "    df.loc[row,'no_stop_cap_lemm'] = str_to_reduce_exclam\n",
    "        \n",
    "df.no_stop_cap_lemm[9255]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ace08d",
   "metadata": {},
   "source": [
    "That worked, move on. \n",
    "\n",
    "<font color='violet'> Deal with null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9027feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>condition</th>\n",
       "      <th>date</th>\n",
       "      <th>drug0</th>\n",
       "      <th>drug1</th>\n",
       "      <th>review_len</th>\n",
       "      <th>complexity</th>\n",
       "      <th>no_stop_cap_lemm</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>original_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rating, condition, date, drug0, drug1, review_len, complexity, no_stop_cap_lemm, subjectivity, original_polarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It appears as though stopword deletion left one very short review consisting of nothing\n",
    "# Drop that row, then reset the index so it's in order. \n",
    "df[df.no_stop_cap_lemm.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f181c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31557 entries, 0 to 31556\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   rating             31557 non-null  float64\n",
      " 1   condition          31557 non-null  object \n",
      " 2   date               31449 non-null  object \n",
      " 3   drug0              31557 non-null  object \n",
      " 4   drug1              18991 non-null  object \n",
      " 5   review_len         31557 non-null  int64  \n",
      " 6   complexity         31557 non-null  float64\n",
      " 7   no_stop_cap_lemm   31557 non-null  object \n",
      " 8   subjectivity       31557 non-null  float64\n",
      " 9   original_polarity  31557 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(labels=29472).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39efefab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating               False\n",
       "condition            False\n",
       "date                  True\n",
       "drug0                False\n",
       "drug1                False\n",
       "review_len           False\n",
       "complexity           False\n",
       "no_stop_cap_lemm     False\n",
       "subjectivity         False\n",
       "original_polarity    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are rows without values for drug1; just replace nan with the string \"na\"\n",
    "df['drug1'] = df.drug1.fillna('na')\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b619398",
   "metadata": {},
   "source": [
    "There are missing dates. I don't want to introduce leakage by imputing missing values with the most common date overall, but I can start with the train_test_split and just impute all missing dates with the most common date from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "496c51e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31557 entries, 0 to 31556\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   rating             31557 non-null  float64       \n",
      " 1   condition          31557 non-null  object        \n",
      " 2   date               31449 non-null  datetime64[ns]\n",
      " 3   drug0              31557 non-null  object        \n",
      " 4   drug1              31557 non-null  object        \n",
      " 5   review_len         31557 non-null  int64         \n",
      " 6   complexity         31557 non-null  float64       \n",
      " 7   no_stop_cap_lemm   31557 non-null  object        \n",
      " 8   subjectivity       31557 non-null  float64       \n",
      " 9   original_polarity  31557 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(4)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# First, turn the date column into a date type\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db14af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22089 entries, 3172 to 30071\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   condition          22089 non-null  object        \n",
      " 1   date               22010 non-null  datetime64[ns]\n",
      " 2   drug0              22089 non-null  object        \n",
      " 3   drug1              22089 non-null  object        \n",
      " 4   review_len         22089 non-null  int64         \n",
      " 5   complexity         22089 non-null  float64       \n",
      " 6   no_stop_cap_lemm   22089 non-null  object        \n",
      " 7   subjectivity       22089 non-null  float64       \n",
      " 8   original_polarity  22089 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns='rating')\n",
    "y = df.rating\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17, \n",
    "                                                    stratify=y)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bdb84ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-02-21    28\n",
       "2016-01-14    24\n",
       "2017-01-25    23\n",
       "2017-01-18    22\n",
       "2015-10-12    22\n",
       "              ..\n",
       "2010-01-14     1\n",
       "2010-02-16     1\n",
       "2008-11-12     1\n",
       "2009-04-15     1\n",
       "2009-03-14     1\n",
       "Name: date, Length: 3503, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.date.value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a25e95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition            False\n",
       "date                 False\n",
       "drug0                False\n",
       "drug1                False\n",
       "review_len           False\n",
       "complexity           False\n",
       "no_stop_cap_lemm     False\n",
       "subjectivity         False\n",
       "original_polarity    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['date'] = X_train.date.fillna('2016-02-21')\n",
    "X_test['date'] = X_test.date.fillna('2016-02-21')\n",
    "X_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5c81111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition            False\n",
       "date                 False\n",
       "drug0                False\n",
       "drug1                False\n",
       "review_len           False\n",
       "complexity           False\n",
       "no_stop_cap_lemm     False\n",
       "subjectivity         False\n",
       "original_polarity    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247f5228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22089 entries, 3172 to 30071\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   condition          22089 non-null  object        \n",
      " 1   date               22089 non-null  datetime64[ns]\n",
      " 2   drug0              22089 non-null  object        \n",
      " 3   drug1              22089 non-null  object        \n",
      " 4   review_len         22089 non-null  int64         \n",
      " 5   complexity         22089 non-null  float64       \n",
      " 6   no_stop_cap_lemm   22089 non-null  object        \n",
      " 7   subjectivity       22089 non-null  float64       \n",
      " 8   original_polarity  22089 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefc4c8",
   "metadata": {},
   "source": [
    "Ready to carry on with feature engineering\n",
    "\n",
    "<font color='violet'> Implement tfidf \n",
    "    \n",
    "I'll need to quickly create and evaluate a model after implementing each method of feature extraction from the no_stop_cap_lemm text. I'll do model tuning later, but for now, my understanding is that naive bayes is a common, solid model for nlp classification tasks, so I'll use that to compare various preprocessing techniques explored here. \n",
    "    \n",
    "I'll start by modeling with just the extracted text features. These could be recombined with the other columns later (once they're encoded numerically) for improved model performance if I have some reason to do so. But I don't want to do all my modeling including variables like drugs and conditions, because those features will be absent from scraped psychedelic experience reports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74a71031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22089 entries, 3172 to 30071\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   review_len         22089 non-null  int64  \n",
      " 1   complexity         22089 non-null  float64\n",
      " 2   no_stop_cap_lemm   22089 non-null  object \n",
      " 3   subjectivity       22089 non-null  float64\n",
      " 4   original_polarity  22089 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train_models = X_train.drop(columns=['condition', 'date', 'drug0', 'drug1'])\n",
    "X_test_models = X_test.drop(columns=['condition', 'date', 'drug0', 'drug1'])\n",
    "X_train_models.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3829c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3172                                     good give run gas\n",
       "21607    75 mg x daily no noticeable effect 150 mg x da...\n",
       "28990    take 145 mg 10 year fantastic insomnia really ...\n",
       "23881    help stability mood help insomnia start experi...\n",
       "16374                                  crazy eat sleep sit\n",
       "Name: no_stop_cap_lemm, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifically, to get tfidf feature engineering to work, pare it down to just text column\n",
    "X_train_tfidf = X_train_models.no_stop_cap_lemm\n",
    "X_test_tfidf = X_test_models.no_stop_cap_lemm\n",
    "X_train_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d437102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6055234472676633"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Could change parametes to include min_df, max_df, but for now just use a simple version\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), lowercase=False)\n",
    "\n",
    "# Fit to training set, and transform both sets\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf = tfidf.transform(X_test_tfidf)\n",
    "\n",
    "# Run through a model to evaluate accuracy\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_tfidf, y_train)\n",
    "pred = nb_clf.predict_proba(X_test_tfidf)\n",
    "metrics.roc_auc_score(y_test, pred, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd1f24",
   "metadata": {},
   "source": [
    "With only the text itself and no additional features such as sentiment polarity, which is quite well-correlated with rating, the area under the curve is 0.6. Try some other methods for feature engineering with the text column. \n",
    "\n",
    "<font color='violet'> Implement feature engineering with CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2f47233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6497113011239557"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy to create relevant train and test sets\n",
    "X_train_cvect = X_train_models.no_stop_cap_lemm\n",
    "X_test_cvect = X_test_models.no_stop_cap_lemm\n",
    "\n",
    "# Instantiate count vectorizer\n",
    "cvect = CountVectorizer(lowercase=False)\n",
    "\n",
    "# Fit to training set, and transform both sets\n",
    "X_train_cvect = cvect.fit_transform(X_train_cvect)\n",
    "X_test_cvect = cvect.transform(X_test_cvect)\n",
    "\n",
    "# Run through a model to evaluate accuracy\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_cvect, y_train)\n",
    "pred = nb_clf.predict_proba(X_test_cvect)\n",
    "metrics.roc_auc_score(y_test, pred, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7184c",
   "metadata": {},
   "source": [
    "The features created by the count vectorizer worked better with the model than those from tfidf. Given that individual words rather than bigrams or trigrams as arranged here are more likely to show up in unseen data from psychedelic experience reports, it also makes sense to favor count vectorizer from a perspective of avoiding overfitting. \n",
    "\n",
    "Finally, generate word embeddings. There are multiple methods with which to do this such as spacy's pretrained models, Word2Vec, GloVe, or FastText. I'm unsure about relative usability or performance, so play around. I did read that FastText is better for generalization to unknown words than Word2Vec or GloVe, so definitely go there and see if it's feasible, after starting with the simplest tool, spacy. \n",
    "\n",
    "<font color='violet'> Explore word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5865f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with just using the spacy vector value to get average token vectors for each review. \n",
    "\n",
    "nlp = spacy.load('en_core_web_lg') \n",
    "df['vector'] = df['no_stop_cap_lemm'].apply(nlp).apply(lambda text: np.mean([token.vector for \n",
    "                                                                             token in text]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this vector column correlated with the ratings column? \n",
    "sns.boxplot(data=df, x='rating', y='vector').set(ylim=(-0.3,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2369419",
   "metadata": {},
   "source": [
    "It appears as though the mean word vector value for each review isn't very meaningful on its own. However, what about columns that contains each review's similarity to a mega-review that is made up of all of the test set's reviews for just rating 1, rating 2, rating 3, etc? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try creating just one column: similarity with reviews with a rating of 10\n",
    "rating_10_review = ' '.join(df[df['rating']==10]['no_stop_cap_lemm'])\n",
    "rating_10_review = nlp(rating_10_review[:100000])\n",
    "df['similarity_w_10'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_10_review))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='rating', y='similarity_w_10').set(ylim=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d25446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This appears slightly more meaningful than several other variables. Confirm. \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "cmap = sns.diverging_palette(h_neg=0, h_pos=0, s=0, l=0, as_cmap=True)\n",
    "sns.heatmap(df[['rating', 'review_len', 'complexity', 'subjectivity', \n",
    "                'original_polarity', 'vector', 'similarity_w_10']].corr(), linewidths=.1, cmap=cmap, center=0.0, annot=True)\n",
    "plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7079d6f",
   "metadata": {},
   "source": [
    "\"Similarity with 10\" has a stronger correlation with rating than any variable other than polarity. It seems worth it to create more of these vector similarity columns. But, of course, only using the texts from the train set. Return to the train and test sets created earlier, and do any manipulation necessary to create spacy nlp docs for the train set's reviews associated with ratings 1-10. Then, create columns for each.  \n",
    "\n",
    "<font color='violet'> Create columns for vector similarity with meta-reviews based on each rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['set'] = 'train'\n",
    "X_test['set'] = 'test'\n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0710964",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_10_meta = ' '.join(train_set[train_set['rating']==10]['no_stop_cap_lemm'])\n",
    "rating_10_meta = nlp(rating_10_meta[:100000])\n",
    "\n",
    "rating_9_meta = ' '.join(train_set[train_set['rating']==9]['no_stop_cap_lemm'])\n",
    "rating_9_meta = nlp(rating_9_meta[:100000])\n",
    "\n",
    "rating_8_meta = ' '.join(train_set[train_set['rating']==8]['no_stop_cap_lemm'])\n",
    "rating_8_meta = nlp(rating_8_meta[:100000])\n",
    "\n",
    "rating_7_meta = ' '.join(train_set[train_set['rating']==7]['no_stop_cap_lemm'])\n",
    "rating_7_meta = nlp(rating_7_meta[:100000])\n",
    "\n",
    "rating_6_meta = ' '.join(train_set[train_set['rating']==6]['no_stop_cap_lemm'])\n",
    "rating_6_meta = nlp(rating_6_meta[:100000])\n",
    "\n",
    "rating_5_meta = ' '.join(train_set[train_set['rating']==5]['no_stop_cap_lemm'])\n",
    "rating_5_meta = nlp(rating_5_meta[:100000])\n",
    "\n",
    "rating_4_meta = ' '.join(train_set[train_set['rating']==4]['no_stop_cap_lemm'])\n",
    "rating_4_meta = nlp(rating_4_meta[:100000])\n",
    "\n",
    "rating_3_meta = ' '.join(train_set[train_set['rating']==3]['no_stop_cap_lemm'])\n",
    "rating_3_meta = nlp(rating_3_meta[:100000])\n",
    "\n",
    "rating_2_meta = ' '.join(train_set[train_set['rating']==2]['no_stop_cap_lemm'])\n",
    "rating_2_meta = nlp(rating_2_meta[:100000])\n",
    "\n",
    "rating_1_meta = ' '.join(train_set[train_set['rating']==1]['no_stop_cap_lemm'])\n",
    "rating_1_meta = nlp(rating_1_meta[:100000])\n",
    "\n",
    "len(rating_1_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf95179",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rating_2_meta), len(rating_3_meta), len(rating_4_meta), len(rating_5_meta), \n",
    "      len(rating_6_meta), len(rating_7_meta), len(rating_8_meta), len(rating_9_meta), \n",
    "      len(rating_10_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2df8e",
   "metadata": {},
   "source": [
    "For the entire dataset, now that each rating_n_meta doc contains only text from the training set, add a column and fill with each review's similarity to each meta-review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "df = pd.concat([train_set, test_set])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9279875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the columns\n",
    "df['similarity_w_10'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_10_meta))\n",
    "\n",
    "df['similarity_w_9'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_9_meta))\n",
    "\n",
    "df['similarity_w_8'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_8_meta))\n",
    "\n",
    "df['similarity_w_7'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_7_meta))\n",
    "\n",
    "df['similarity_w_6'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_6_meta))\n",
    "\n",
    "df['similarity_w_5'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_5_meta))\n",
    "\n",
    "df['similarity_w_4'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_4_meta))\n",
    "\n",
    "df['similarity_w_3'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_3_meta))\n",
    "\n",
    "df['similarity_w_2'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_2_meta))\n",
    "\n",
    "df['similarity_w_1'] = df.no_stop_cap_lemm.apply(nlp).apply(\n",
    "    lambda text: text.similarity(rating_1_meta))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "cmap = sns.diverging_palette(h_neg=0, h_pos=0, s=0, l=0, as_cmap=True)\n",
    "sns.heatmap(df[['rating', 'similarity_w_10', 'similarity_w_9', 'similarity_w_8', \n",
    "                'similarity_w_7', 'similarity_w_6', 'similarity_w_5', 'similarity_w_4', \n",
    "                'similarity_w_3', 'similarity_w_2', 'similarity_w_1']].corr(), \n",
    "            linewidths=.1, cmap=cmap, center=0.0, annot=True)\n",
    "plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7f331",
   "metadata": {},
   "source": [
    "These columns are highly correlated with one another. Keep just the one column that has the highest correlation with rating, \"similarity_w_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175414d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['similarity_w_9', 'similarity_w_8', 'similarity_w_7', 'similarity_w_6', \n",
    "                      'similarity_w_5', 'similarity_w_4', 'similarity_w_3', 'similarity_w_2', \n",
    "                      'similarity_w_1'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7332d8f7",
   "metadata": {},
   "source": [
    "Several of these columns so far, if combined with the feature engineering done by CountVectorizer, could support solid modeling. Get started with that now, come back later to try more advanced techniques. \n",
    "\n",
    "With FastText, I'll use a pre-trained model and just update it because I don't want to limit my model to words present in this dataset. \n",
    "\n",
    "<font color='violet'> Explore FastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431157d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5173a144",
   "metadata": {},
   "source": [
    "I drew some code from these resources: \n",
    "- https://www.kaggle.com/code/abhishek/approaching-almost-any-nlp-problem-on-kaggle/notebook\n",
    "\n",
    "\n",
    "Resources related to FastText:\n",
    "- https://fasttext.cc/docs/en/python-module.html\n",
    "- https://www.kaggle.com/code/grantgasser/eda-naive-bayes-bert-glove-fasttext-nn\n",
    "- https://pythonwife.com/fasttext-in-nlp/\n",
    "- https://towardsdatascience.com/fasttext-for-text-classification-a4b38cbff27c\n",
    "- https://towardsdatascience.com/sarcasm-classification-using-fasttext-788ffbacb77b\n",
    "- - https://thinkinfi.com/fasttext-word-embeddings-python-implementation/\n",
    "\n",
    "\n",
    "Other resources to check out:\n",
    "- Try using huggingface based on example here: https://towardsdatascience.com/a-beginners-guide-to-use-bert-for-the-first-time-2e99b8c5423\n",
    "- re: using spacy's visualizer: https://medium.com/acing-ai/visualizations-in-natural-language-processing-2ca60dd34ce\n",
    "- Or visualize word embeddings with t-sne\n",
    "- Come back to this resource used in the previous notebook; it also contains info re: visualizing word embeddings: Still especially interested in digging deeper with visualizing word embeddings: https://medium.com/plotly/nlp-visualisations-for-clear-immediate-insights-into-text-data-and-outputs-9ebfab168d5b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a312e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/interim/studies_w_vector_similarity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1556987",
   "metadata": {},
   "source": [
    "Final model selection and tuning here: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
