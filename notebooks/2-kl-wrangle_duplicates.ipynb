{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2d0283",
   "metadata": {},
   "source": [
    "# <font color='violet'> Further Cleaning of Duplicate Reviews\n",
    "Using prescription drug review initially wrangled here wrangled here: https://github.com/fractaldatalearning/psychedelic_efficacy/blob/main/notebooks/1-kl-wrangle-tabular.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d794ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1fb33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50637 entries, 0 to 50636\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  50637 non-null  int64  \n",
      " 1   drug        50637 non-null  object \n",
      " 2   rating      50637 non-null  float64\n",
      " 3   condition   50637 non-null  object \n",
      " 4   review      50637 non-null  object \n",
      " 5   date        50637 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/studies_initial_cleaning.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "befb84a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>rating</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vyvanse</td>\n",
       "      <td>9.0</td>\n",
       "      <td>add</td>\n",
       "      <td>I had began taking 20mg of Vyvanse for three m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dextroamphetamine</td>\n",
       "      <td>8.0</td>\n",
       "      <td>add</td>\n",
       "      <td>Switched from Adderall to Dexedrine to compare...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                drug  rating condition  \\\n",
       "0            vyvanse     9.0       add   \n",
       "1  dextroamphetamine     8.0       add   \n",
       "\n",
       "                                              review date  \n",
       "0  I had began taking 20mg of Vyvanse for three m...    0  \n",
       "1  Switched from Adderall to Dexedrine to compare...    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"Unnamed\" column; it's redundant with the index\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f0d34",
   "metadata": {},
   "source": [
    "During EDA, I discovered that many reviews are duplicated. It seems that what I discovered is one person may have just written one big review for all their drugs and entered it multiple times, with a different drug and rating each time. Is this behavior an outlier or are there many examples like this? \n",
    "\n",
    "<font color='violet'> Decide what to do about duplicated reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78254eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>rating</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Quetiapine</td>\n",
       "      <td>9.0</td>\n",
       "      <td>depression</td>\n",
       "      <td>\"been great for me except for the weight gain ...</td>\n",
       "      <td>October 23, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>addiction</td>\n",
       "      <td>\"I was on suboxone strips which was working gr...</td>\n",
       "      <td>June 28, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Desvenlafaxine</td>\n",
       "      <td>4.0</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>\"I am into my 4th week of Pristiq and it hasn&amp;...</td>\n",
       "      <td>October 8, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Suboxone</td>\n",
       "      <td>9.0</td>\n",
       "      <td>addiction</td>\n",
       "      <td>\"My personal experience with suboxone is good ...</td>\n",
       "      <td>May 27, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Lorazepam</td>\n",
       "      <td>8.0</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>\"Most subtle of the benzos i have tried.  Made...</td>\n",
       "      <td>October 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50631</th>\n",
       "      <td>Geodon</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bipolar</td>\n",
       "      <td>\"I was in a very bad place at the time I start...</td>\n",
       "      <td>July 25, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50632</th>\n",
       "      <td>Venlafaxine</td>\n",
       "      <td>9.0</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>\"Had panic attacks and social anxiety starting...</td>\n",
       "      <td>November 10, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50634</th>\n",
       "      <td>Ativan</td>\n",
       "      <td>9.0</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>\"I was super against taking medication. I&amp;#039...</td>\n",
       "      <td>August 16, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50635</th>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ocd</td>\n",
       "      <td>\"I have been off Prozac for about 4 weeks now....</td>\n",
       "      <td>January 21, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50636</th>\n",
       "      <td>Campral</td>\n",
       "      <td>10.0</td>\n",
       "      <td>addiction</td>\n",
       "      <td>\"I wrote my first report in Mid-October of 201...</td>\n",
       "      <td>May 31, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19078 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           drug  rating   condition  \\\n",
       "668                  Quetiapine     9.0  depression   \n",
       "686    Buprenorphine / naloxone     1.0   addiction   \n",
       "732              Desvenlafaxine     4.0     anxiety   \n",
       "816                    Suboxone     9.0   addiction   \n",
       "821                   Lorazepam     8.0     anxiety   \n",
       "...                         ...     ...         ...   \n",
       "50631                    Geodon     3.0     bipolar   \n",
       "50632               Venlafaxine     9.0     anxiety   \n",
       "50634                    Ativan     9.0     anxiety   \n",
       "50635                Fluoxetine     8.0         ocd   \n",
       "50636                   Campral    10.0   addiction   \n",
       "\n",
       "                                                  review               date  \n",
       "668    \"been great for me except for the weight gain ...   October 23, 2016  \n",
       "686    \"I was on suboxone strips which was working gr...      June 28, 2017  \n",
       "732    \"I am into my 4th week of Pristiq and it hasn&...    October 8, 2011  \n",
       "816    \"My personal experience with suboxone is good ...       May 27, 2017  \n",
       "821    \"Most subtle of the benzos i have tried.  Made...   October 28, 2013  \n",
       "...                                                  ...                ...  \n",
       "50631  \"I was in a very bad place at the time I start...      July 25, 2016  \n",
       "50632  \"Had panic attacks and social anxiety starting...  November 10, 2016  \n",
       "50634  \"I was super against taking medication. I&#039...    August 16, 2016  \n",
       "50635  \"I have been off Prozac for about 4 weeks now....   January 21, 2015  \n",
       "50636  \"I wrote my first report in Mid-October of 201...       May 31, 2015  \n",
       "\n",
       "[19078 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.review.duplicated()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd97283",
   "metadata": {},
   "source": [
    "Many rows actually contain duplicate reviews, each connected with multiple different drugs. Did the data start out this way, or did I make an error during initial wrangling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_dotcom_train = pd.read_csv('../data/raw/drugsComTrain_raw.tsv', sep='\\t')\n",
    "drugs_dotcom_test = pd.read_csv('../data/raw/drugsComTest_raw.tsv', sep='\\t')\n",
    "druglib_train = pd.read_csv('../data/raw/drugLibTrain_raw.tsv', sep='\\t')\n",
    "druglib_test = pd.read_csv('../data/raw/drugLibTest_raw.tsv', sep='\\t')\n",
    "psytar = pd.read_csv('../data/raw/PsyTAR_dataset_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to help figure out what's going on \n",
    "def inspect_duplicate_reviews(df, column):\n",
    "    df = df.sort_values(by=column)\n",
    "    print(len(df), len(df[df[column].duplicated()==True]))\n",
    "    return df[df[column].duplicated()==True].head()\n",
    "\n",
    "# What my current working data looks like\n",
    "inspect_duplicate_reviews(df, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cbb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out each of the other raw datasets\n",
    "drugs_dotcom_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac61dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_duplicate_reviews(drugs_dotcom_train, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7727a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30% of the original reviews from that set were duplicates. \n",
    "inspect_duplicate_reviews(drugs_dotcom_test, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1773682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of drugs_dotcom_test was duplicates\n",
    "druglib_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c33c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_duplicate_reviews(druglib_train, 'commentsReview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89633a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fewer of these were duplicates\n",
    "psytar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_duplicate_reviews(psytar, 'comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adec8c",
   "metadata": {},
   "source": [
    "This last raw dataset has about 15% duplicate values but few rows overall. \n",
    "\n",
    "I did go back to the wrangling notebook and don't see any errors that would have caused this. I think I just didn't notice earlier because I would expect there to be duplicates in many of the columns (drug, condition) without it being a problem at all. Or perhaps completely duplicated rows, and took care of those. But it didn't cross my mind to think that specifically the reveiw column would have duplicates across multiple drugs. \n",
    "\n",
    "There are enough duplicated reviews in the raw data to account for all the duplicates in my current dataframe. My best working hypothesis is that the duplicate reviews appeared more often with psych meds because people may cycle through and try many drugs and then write up one big narrative to submit. Or perhaps, they feel one way about the drug's effects and go back to change their rating later, which results in two rows varying only by rating. I may need to more closely inspect each set of duplicates and find out which drugs the reviews are actually relevant for, removing the rest of the rows. \n",
    "\n",
    "<font color='violet'> Remove rows with irrelevant duplicated reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with just one set of duplicates and see what I find.\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9dab07",
   "metadata": {},
   "source": [
    "It appears that somebody submitted the same review for vyvanse, dextroamphetamine, saizen, and zyprexa. And with vyvanse, they submitted it as being used to treat both add and adhd. And for add they gave it a rating of 9 with one submission and 10 with another. \n",
    "\n",
    "I can see already that this definitly pertains to vyvanse. Since the add ratings are ambiguous, I can just get rid of those and keep the row for adhd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=[0,5])\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a closer look at the full review to see if it pertains to the other drugs.\n",
    "df.review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only pertains to vyvanse. Drop other rows. \n",
    "df = df.drop(labels=[1,3,4])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a29fd",
   "metadata": {},
   "source": [
    "How many sets of duplicates will I need to work with? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.review.duplicated()==True]['review'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d03b16",
   "metadata": {},
   "source": [
    "There are so many sets of duplicates, I'm going to need to find some way to do automated/batch deletion.\n",
    "\n",
    "This could be a place to group by the review until there's just one row per review with various drug/rating/condition combinations that can be aggregated for each set of duplicates or analyzed more easily in batches for quicker identification of values to keep or delete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a columm where I can hold whether each row should be kept or deleted. \n",
    "# Work until every row is filled with a value, then delete indicated rows.\n",
    "df['keep'] = ''\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e14d8d2",
   "metadata": {},
   "source": [
    "<font color='violet'> First, mark for keeping any non-duplicate reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d71f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.review.duplicated(keep=False)==False),'keep'] = 'yes'\n",
    "df[df.review.duplicated(keep=False)==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4000b45",
   "metadata": {},
   "source": [
    "<font color='violet'> Mark for keeping any rows where the name of the drug is contained in the text of the review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['review', 'drug']).count()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row indices are defined by the drug column. Gather indices for reviews to keep.\n",
    "grouped_df_indices_to_keep = []\n",
    "\n",
    "# Find if the review column contains the string from the drug column.\n",
    "for row in range(len(grouped_df.index)):\n",
    "    if (grouped_df.index[row][1].lower() in grouped_df.index[row][0].lower()) == True:\n",
    "        grouped_df_indices_to_keep.append(row)\n",
    "        \n",
    "grouped_df_indices_to_keep[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee119907",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped_df_indices_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems many rows should be kept. Check that this worked correctly.\n",
    "grouped_df.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca439af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The drug name is in the review narrative. \n",
    "# Isolate just the rows to keep\n",
    "grouped_to_keep = pd.MultiIndex.to_frame(grouped_df.index[grouped_df_indices_to_keep])\n",
    "grouped_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54183088",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_to_keep = grouped_to_keep.reset_index(drop=True)\n",
    "grouped_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the correct number of rows for reviews that contain the drug name\n",
    "# Add the keep row so that this df can be merged with the original df\n",
    "grouped_to_keep['keep'] = 'yes'\n",
    "grouped_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3845ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(right=grouped_to_keep, how='left', on=['review', 'drug'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c83fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This contains the correct number of rows to match the original df\n",
    "# keep_y has the values I need for knowing which rows to keep so far\n",
    "\n",
    "df = df.drop(columns=['keep_x'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'keep_y':'keep'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill na in keep column to make it easier to work with later.\n",
    "df['keep'] = df.keep.fillna('z')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db02ed",
   "metadata": {},
   "source": [
    "Dig further into rows where the name of the drug is not in the review. This does not necessarily mean the review isn't applicable to the associated drug. But, I'd say that if there is a review that contains a drug name, that same review should be dropped wherever it appears along with a different drug not mentioned. \n",
    "\n",
    "<font color='violet'> Drop rows where text doesn't contain drug name but drug name is present in the same review for a different drug. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d718553",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_drug_in_review = df.groupby(['review', 'keep']).count().sort_values(\n",
    "    by=['review', 'keep'])\n",
    "no_drug_in_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_drug_in_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caddcafc",
   "metadata": {},
   "source": [
    "There are fewer indices this time because some rows have multiple drugs aggregated within the 'z' row for a review. If a review has only unknown (z) keep values, that should remain unknown for now. But if there is a yes row for the review, then that review's z's should be come no's. \n",
    "\n",
    "Specifically, identify reviews for rows to keep. Then, since yes comes before z in the sorting, the yes row is on top in each set of rows per review. So, the row directly below each yes row can be deleted, IF it has the same review. (If it doesn't have the same review, then it should remain unknown for now). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_drop = []\n",
    "\n",
    "for idx in range(len(no_drug_in_review)):\n",
    "    # Isolate reviews for rows to keep, and if  \n",
    "    if (no_drug_in_review.index[idx][1] == 'yes' and no_drug_in_review.index[idx][0] == \n",
    "        no_drug_in_review.index[idx+1][0]):\n",
    "        indices_to_drop.append(idx+1)\n",
    "\n",
    "indices_to_drop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120da413",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ed093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm this worked correctly\n",
    "no_drug_in_review.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_drug_in_review.index[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c13b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This worked correctly. Index 2 is slotted for dropping, and it has the same review as \n",
    "# index 1, which is labeled yes to keep. Now, isolate the rows to drop.\n",
    "\n",
    "un_reviewed_to_drop = pd.MultiIndex.to_frame(no_drug_in_review.index[indices_to_drop])\n",
    "un_reviewed_to_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1055a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_reviewed_to_drop = un_reviewed_to_drop.reset_index(drop=True)\n",
    "un_reviewed_to_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change keep value to no\n",
    "un_reviewed_to_drop['keep'] = 'no'\n",
    "un_reviewed_to_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d7c94",
   "metadata": {},
   "source": [
    "This can again be merged with df. There may be multiple drugs per \"no keep\" review, and that's okay; each one can be filled with no because these reviews should be dropped wherever they appear, since they already have an associated yes review that is definitely relevant to its associated drug. Wherever the new keep column says no but the old keep column says yes, the value should be yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(right=un_reviewed_to_drop, on='review', how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, if keep_x = yes, that's the row to keep for that review. \n",
    "# anyplace where keep_x = z but keep_y = no, the keep value should end up as no\n",
    "\n",
    "for row in range(len(df)):\n",
    "    if df.loc[row,'keep_y'] == 'no' and df.loc[row,'keep_x'] == 'z':\n",
    "        df.loc[row,'keep_x'] = 'no'\n",
    "\n",
    "df[df.keep_y=='no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b43cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if this worked correctly\n",
    "df[df.review == df.loc[122,'review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ec634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks correct. The drug name is in the review associated with the yes row\n",
    "# The matching review now says no in keep_x. I can delete the row keep_y\n",
    "\n",
    "df = df.drop(columns=['keep_y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98162a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'keep_x':'keep'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c119b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What remains? How many rows still have a keep value of z?\n",
    "len(df[df.keep=='z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476df06",
   "metadata": {},
   "source": [
    "<font color='violet'> Deal with any reviews that are just duplicates related to multiple conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40116423",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_condition = df.groupby(['review', 'condition']).count()\n",
    "grouped_by_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8768dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those duplicated by condition would show up where 2 subsequent indices have the same review.\n",
    "indices_duplicated_by_condition = []\n",
    "for idx in range(len(grouped_by_condition)):\n",
    "    # Need to include a try-except since sometimes idx+1 won't exist\n",
    "    try:\n",
    "        if grouped_by_condition.index[idx][0] == grouped_by_condition.index[idx+1][0]:\n",
    "            indices_duplicated_by_condition.append(idx)\n",
    "            indices_duplicated_by_condition.append(idx+1)\n",
    "    except: pass\n",
    "        \n",
    "indices_duplicated_by_condition[:5]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the rows I've identified\n",
    "duplicated_by_condition = pd.MultiIndex.to_frame(grouped_by_condition.index[\n",
    "    indices_duplicated_by_condition])\n",
    "duplicated_by_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d1a74",
   "metadata": {},
   "source": [
    "Here, I think it would make sense to just choose one of the conditions to keep. If there were many pairs like this, I might create columns \"condition1\" and \"condition2\", but if \"condition2\" would only have 4 values out of tens of thousands of rows, that seems like a waste. Instead, I'll go ahead and just keep the row for the less-common condition, so as to balance rather than further un-balance the condition column. \n",
    "\n",
    "First I'll need a dictionary of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_rank = df.condition.value_counts().to_frame()\n",
    "conditions_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd25695",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_rank['rank'] = range(len(conditions_rank))\n",
    "conditions_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2dac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_rank = conditions_rank.drop(columns=['condition']).reset_index().rename(\n",
    "    columns={'index':'condition'})\n",
    "conditions_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_rank = conditions_rank.set_index('condition').to_dict()['rank']\n",
    "conditions_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe of just reviews that have multiple conditions attached\n",
    "duplicated_by_condition = duplicated_by_condition.reset_index(drop=True)\n",
    "duplicated_by_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get this in a format where the conditions for each review can be compared\n",
    "for row in range(len(duplicated_by_condition)):\n",
    "    duplicated_by_condition.loc[row,'rank'] = conditions_rank[duplicated_by_condition.loc[\n",
    "        row, 'condition']]\n",
    "\n",
    "duplicated_by_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify max rank as the condition to keep for each review\n",
    "condition_to_keep = duplicated_by_condition.groupby(['review']).max()\n",
    "condition_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the wrong condition listed, but the correct condition rank that should be kept.\n",
    "\n",
    "condition_to_keep = condition_to_keep.drop(columns=['condition'])\n",
    "condition_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change rank to int type\n",
    "condition_to_keep['rank'] = condition_to_keep['rank'].astype(int)\n",
    "condition_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d36889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regular df to iterate through:\n",
    "condition_to_keep = condition_to_keep.reset_index()\n",
    "condition_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2179453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refill conditions \n",
    "for row in range(len(condition_to_keep)):\n",
    "    for key, value in conditions_rank.items():\n",
    "        if condition_to_keep.loc[row,'rank'] == value:\n",
    "                condition_to_keep.loc[row,'condition'] = key\n",
    "            \n",
    "condition_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63675d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These conditions should have a keep value of 'yes'\n",
    "condition_to_keep['keep'] = 'yes'\n",
    "condition_to_keep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with duplicated_by_condition so as to be able to mark remaining rows with \"no\"\n",
    "duplicated_by_condition = duplicated_by_condition.merge(condition_to_keep, how='left')\n",
    "duplicated_by_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_by_condition = duplicated_by_condition.drop(columns=['rank']).fillna('no')\n",
    "duplicated_by_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ecbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now duplicated_by_condition can be merged with the rest of the df\n",
    "df = df.merge(duplicated_by_condition, on=['review', 'condition'], how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad295bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How did that work? What does the first review with duplicated conditions look like?\n",
    "df[df.review.str.contains('After many months spent being given ten')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'd previously mis-labeled some rows. \n",
    "df.sort_values(by=['keep_y', 'keep_x']).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89895b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wherever keep_y is not null, that is the value that should be kept. \n",
    "# Otherwise keep the value of keep_y\n",
    "\n",
    "df = df.reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(df)):\n",
    "    if df.loc[row,'keep_y'] == 'yes' or df.loc[row,'keep_y'] == 'no':\n",
    "        df.loc[row,'keep'] = df.loc[row,'keep_y']\n",
    "    else: df.loc[row,'keep'] = df.loc[row,'keep_x']\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['keep_y', 'keep_x']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e04bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks correct so far. Clean up. \n",
    "df = df.drop(columns=['keep_x', 'keep_y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f430506",
   "metadata": {},
   "source": [
    "Now, everywhere there is a duplicated review, a row for that review is being kept if it contains the drug name and it is submitted for the least-common condition. Reviews are marked for removal if they don't contain the name of the drug but their duplicate does. And being removed if submitted for a more-common condition where the review is also submitted for a less-common condition. \n",
    "\n",
    "But, wherever there is no drug name at all in the review, duplicates likely still exist across multiple drugs. This may be a place where new columns for drug1, drug2, drug3 may be necessary\n",
    "\n",
    "<font color='violet'> Deal with remaining reviews duplicated across multiple drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many reviews remain to deal with?\n",
    "len(df[(df.review.duplicated(keep=False)==True) & (df.keep=='z')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe67980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the highest number of drugs associated with a single review?\n",
    "row_count = df.groupby(['review']).count()\n",
    "row_count.sort_values(by='drug', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344c8a1",
   "metadata": {},
   "source": [
    "The review \"Good\" is associated with 16 different drugs. Add columns drug0...drug15 wherever a review has more than one associated drug. First, sort drugs by prevalance, then enumerate drugs per review so that column can then become multiple nuew columns. Finally, create a pivot table and fill values of new drug_n columns with drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769af516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back and sort drugs according to how common they are so they're enumerated that way\n",
    "by_drug = df.groupby('drug').count().sort_values(by='rating', ascending=False)\n",
    "by_drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_drug['drug_prevalance'] = range(len(by_drug))\n",
    "by_drug = by_drug.drop(columns=[\n",
    "    'rating', 'condition', 'review', 'date', 'keep']).reset_index()\n",
    "by_drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df so that drugs have their prevalance values associated\n",
    "df = df.merge(by_drug, how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678fad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create drug_n to enumerate drugs per review\n",
    "df['drug_n'] = df.sort_values(by='drug_prevalance').groupby(['review']).cumcount()\n",
    "df.sort_values(by=['review', 'drug_n'])\n",
    "df.drug_n.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That appears to have worked. drug_n should contain values 0:15, for max 15 duplicates/review\n",
    "# Now fill in values for some new drug_n columns\n",
    "wide_df = pd.pivot(data=df, columns='drug_n', values='drug', index='review')\n",
    "wide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs are now distributed across rows 0-15. Get this in a format to re-merge w/ full df\n",
    "wide_df = wide_df.reset_index().rename(columns={0:'drug0', 1:'drug1', 2:'drug2', 3:'drug3', \n",
    "                                                4:'drug4', 5:'drug5', 6:'drug6', 7:'drug7', \n",
    "                                                8:'drug8', 9:'drug9', 10:'drug10', 11:'drug11', \n",
    "                                                12:'drug12', 13:'drug13', 14:'drug14', \n",
    "                                                15:'drug15'})\n",
    "wide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_cols_df = df.merge(wide_df, on='review', how='left')\n",
    "drug_cols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78345d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has the correct number and type of rows and columns. Clean up columns. \n",
    "drug_cols_df = drug_cols_df.drop(columns=['drug', 'drug_prevalance', 'drug_n'])\n",
    "drug_cols_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12d2a3",
   "metadata": {},
   "source": [
    "This is now in a format where there are (hopefully) completely duplicated rows. Reviews with duplicates and a keep value of z should now all have the same drugs associated with them, just spread over multiple columns. See if it works to simply drop completely duplicate rows. \n",
    "\n",
    "<font color='violet'> Delete duplicates and rows marked for deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d11d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_cols_df = drug_cols_df.drop_duplicates()\n",
    "drug_cols_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That did get rid of 7k rows. \n",
    "drug_cols_df = drug_cols_df[drug_cols_df.keep!='no'].copy()\n",
    "drug_cols_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af310b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another 10k rows taken care of. Check out what's up now with duplicated reviews\n",
    "len(drug_cols_df[drug_cols_df.review.duplicated(keep=False)==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very easy to deal with now\n",
    "drug_cols_df[drug_cols_df.review.duplicated(keep=False)==True].sort_values(by='review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874bbc1",
   "metadata": {},
   "source": [
    "Remaining duplicates were reviews that were either identical and submitted on two different dates or varied only by their rating. I'll just keep the latest review. \n",
    "\n",
    "<font color='violet'> Nuke remaining duplicate reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e03773",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = [28271, 17638, 3750, 919, 42884, 5937, 972, 31390]\n",
    "final_df = drug_cols_df.drop(index=rows_to_drop).drop(columns=['keep'])\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a7cae",
   "metadata": {},
   "source": [
    "There are null values here, but they are truly null. They'll need to be changed prior to modeling, but for the purposes of EDA they should be kept. This should finally be ready to use for EDA. Pick that up in the next notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e315210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../data/interim/studies_no_duplicates.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
